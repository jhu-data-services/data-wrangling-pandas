{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Data Wrangling in Python\n",
    "## Introduction to the pandas library, part 1\n",
    "### [dataservices.library.jhu.edu](https://dataservices.library.jhu.edu/)\n",
    "#### Reina Chano Murray, JHU Data Services\n",
    "#### Date: February 27, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### Introduction\n",
    "[Software and materials](#Software-and-materials)   \n",
    "[Pre-requisites](#Pre-requisites)   \n",
    "[Learning objectives](#Today,-you-will-learn:)   \n",
    "\n",
    "#### Section 1: Temperatures dataset\n",
    "[pandas Overview](#pandas:-a-Python-library-for-data-analysis)   \n",
    "[Exercise 1: Why use pandas?](#Exercise-1:-Why-use-pandas?)   \n",
    "\n",
    "[Data structures: Series and DataFrame](#Data-structures:-Series-and-DataFrame)     \n",
    "[Exercise 2: Create a Series object](#Exercise-2:-Create-a-Series-object)   \n",
    "[Exercise 3: Create a DataFrame](#Exercise-3:-Create-a-DataFrame)   \n",
    "[Exercise 4: Exploring a DataFrame](#Exercise-4:-Exploring-a-DataFrame)   \n",
    "[Exercise 5: Subsetting a DataFrame](#Exercise-5:-Subsetting-a-DataFrame)   \n",
    "[Exercise 6: Adding and renaming columns](#Exercise-6:-Adding-and-renaming-columns)   \n",
    "\n",
    "#### Section 2: Palmer Penguins dataset\n",
    "[More data manipulation](#More-data-manipulation)   \n",
    "[Exercise 7: Exploratory data analysis](#Exercise-7:-Exploratory-data-analysis)   \n",
    "[Exercise 8: Dealing with missing values](#Exercise-8:-Dealing-with-missing-values)   \n",
    "[Exercise 9: Sorting data](#Exercise-9:-Sorting-data)\n",
    "\n",
    "#### Summary\n",
    "[Summary](#Summary)  \n",
    "[Questions?](#Questions?)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Software and materials     \n",
    "\n",
    "- Jupyter Notebooks or JupyterLab ([Anaconda distribution](https://www.anaconda.com/products/individual) recommended)   \n",
    "    - Please install the following libraries:\n",
    "        - `pandas`\n",
    "- Zip folder from the Data Service [github repo](https://github.com/jhu-data-services/data-wrangling-pandas) containing:\n",
    "    - DataWranglingPandas_InClass.ipynb\n",
    "    - Images folder\n",
    "    - Data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pre-requisites:\n",
    "\n",
    "- Knowledge of basic programming concepts\n",
    "    - Data types\n",
    "    - Variable assignment\n",
    "    - Function calls\n",
    "- Introductory experience in Python or R (e.g., Data Services Intro to Python or Intro to R workshops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this Webinar\n",
    "\n",
    "#### Recording\n",
    "This workshop will be recorded. Recording will be stopped during Q&A. An edited version of this recording will be made available for JHU patrons to access via Panopto later in the semester. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 2-part series\n",
    "Today is part 1 of a 2 part series. Part 2 will take place on **March 6, 2023** from 1-3 pm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "<div class=\"alert alert-info\">\n",
    "    <p>Over the course of this 2-part webinar series, students will learn:\n",
    "        <ul>\n",
    "            <li>what the pandas library is</li>\n",
    "            <li>the two primary data structures of the pandas library: Series and DataFrame</li>\n",
    "            <li>How to implement functions from the pandas library to explore and manipulate a dataset, including:\n",
    "                <ul>\n",
    "                    <li>Exploratory data analysis</li>\n",
    "                    <li>Subsetting or filtering data</li>\n",
    "                    <li>Handling missing data</li>\n",
    "                    <li>Sorting data</li>\n",
    "                    <li>Calculating basic summary statistics</li>\n",
    "                    <li>Grouping data</li>\n",
    "                    <li>Joining data</li>\n",
    "                </ul></li>\n",
    "            <li>How to review documentation and reference information for pandas</li>\n",
    "         </ul>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='./Images/DataServicesAbout.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Note: the copy of these materials you have downloaded is YOURS\n",
    "\n",
    "Add notes, write additional code or comments, mark up the document in a way that is helpful to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='./Images/pandas-logo.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h3> Section 1: Temperatures dataset </h3>\n",
    "    <h4>In this section:</h4> \n",
    "    \n",
    "[pandas Overview](#pandas:-a-Python-library-for-data-analysis)  \n",
    "- [Exercise 1: Why use pandas?](#Exercise-1:-Why-use-pandas?)   \n",
    "    \n",
    "[Data structures: Series and DataFrame](#Data-structures:-Series-and-DataFrame)  \n",
    "- [pandas Series](#pandas-Series)   \n",
    "- [Exercise 2: Create a Series object](#Exercise-2:-Create-a-Series-object)   \n",
    "    \n",
    "[pandas DataFrame](#pandas-DataFrame)   \n",
    "- [Exercise 3: Create a DataFrame](#Exercise-3:-Create-a-DataFrame)   \n",
    "- [Exercise 4: Exploring a DataFrame](#Exercise-4:-Exploring-a-DataFrame)   \n",
    "- [Exercise 5: Subsetting a DataFrame](#Exercise-5:-Subsetting-a-DataFrame)   \n",
    "- [Exercise 6: Adding and renaming columns](#Exercise-6:-Adding-and-renaming-columns)   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pandas: a Python library for data analysis\n",
    "The `pandas` library is an open-source Python library that helps you work with data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Supports a full data analysis workflow:\n",
    "    - data cleaning\n",
    "    - data exploration\n",
    "    - data transformation (merging, joining, reshaping, pivoting)\n",
    "    - data analysis\n",
    "    - data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Works with a range of data formats (CSV, Excel, JSON, XML, SQL, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Similar structure to R programming language (DataFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Especially good for time series data, statistics, machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Documentation: [https://pandas.pydata.org/docs/index.html](https://pandas.pydata.org/docs/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 1: Why use pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Below is a list of temperatures in Fahrenheit. In an empty code cell, write some Python code to convert the temperatures from Fahrenheit to Celsius. Assign the new temperatures to a new list called <code>temps_c</code> </div>\n",
    "\n",
    "The formula to convert Fahrenheit to Celsius is\n",
    "<br>\n",
    "$${\\frac {F-32}{1.8}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_f = [66, 70, 66, 64, 64, 59, 52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to convert temps_f to Celsius\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data structures: Series and DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A one-dimensional array\n",
    "    - Similar to a spreadsheet with 1 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Can hold any data type (integer, string, float, python objects, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Row (axis) labels are called the **index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exercise 2: Create a Series object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Create a pandas Series using our list of temperatures in Fahrenheit, <code>temps_f</code>. Then use the pandas library to convert the temperatures to Celsius. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform list temps_f into a pandas series named temps_series_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_series_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `temps_series_f`, the left column (0, 1, 2, 3,...) is the index. The right column (66, 70, 66...) is our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# convert the Fahrenheit values in temp_series_f to Celsius, saved in a variable named temp_series_c\n",
    "# reminder: celsius = (temp_f - 32) / 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_series_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### pandas Series - some useful attributes and methods\n",
    "For more information on series, view its [documentation](https://pandas.pydata.org/docs/reference/series.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how big is our series?\n",
    "temps_series_c.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are all the values unique?\n",
    "temps_series_c.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see number of occurrences of each value in a series\n",
    "temps_series_c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# look at just the top or last n rows\n",
    "temps_series_c.head()   # returns top n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_series_c.tail()   # returns last n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# aggregations\n",
    "\n",
    "# what is the average temperature recorded?\n",
    "temps_series_c.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the median temperature recorded?\n",
    "temps_series_c.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the highest temperature recorded?\n",
    "temps_series_c.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the lowest temperature recorded?\n",
    "temps_series_c.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort Series in order of smallest to largest temperature\n",
    "temps_series_c.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A two-dimensional array\n",
    "    - Similar to a spreadsheet with multiple columns, or many Series combined\n",
    "    - will also have a header row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Can hold any data type\n",
    "    - different columns can hold different data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Row (axis 0) labels are called the index\n",
    "- Column (axis 1) labels are called columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3: Create a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Create a dataframe, called <code>df</code>, using our list of temperatures <code>temps_f</code> and the below list of days of the week <code>days_list</code>.<br>The temperatures listed in <code>temps_f</code> represent estimated high temperatures for a recent week in Baltimore.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_list = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways we can create a dataframe from Python lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    Option 1: Create an empty DataFrame, then add our lists as new columns</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe named df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax to add a new column is `dataframe[col_name] = data_for_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column temps_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Option 2: Combine our two lists into a Python dictionary, then create a DataFrame from the dictionary</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine days and temps_f into a Python dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame from dictionary object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5 minute break\n",
    "When we come back: Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4: Exploring a DataFrame\n",
    "In this section, we will find basic information about our dataframe and start to manipulate our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`pandas` has many methods and attributes to help us explore a new dataset. Here are a few of them:  \n",
    "\n",
    "| Syntax | Description |\n",
    "| :----------- | :----------- |\n",
    "| **.head()** | returns first 5 rows [default, put desired number of rows in the parentheses] |\n",
    "| **.tail()** | returns last 5 rows [default, put desired number of rows in the parentheses] |\n",
    "| **.sample()** | returns random sample of the dataframe |\n",
    "| **.dtypes** | returns data type of each column |\n",
    "| **.shape** | returns tuple representing the dimensionality of the dataframe (rows, columns) |\n",
    "| **.axes** | returns list representing axes of the dataframe |\n",
    "| **.info** | prints a summary of the dataframe |\n",
    "| **.columns** | returns column names |\n",
    "| **.unique()** | returns unique values for a given column or Series. *Note*: Must use this function on an individual column in a DataFrame, or on a singular Series |\n",
    "| **.describe()** | returns summary statistics for numeric columns |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why do some of these have parentheses and some do not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are two programming paradigms in Python: **procedural** (or sequential) programming, and **object-oriented programming** (OOP).  \n",
    "\n",
    "Python libraries, including pandas, use object-oriented programming. In object-oriented programming, you create **classes**.  \n",
    "\n",
    "Pandas DataFrames and Series are both classes; when we create a DataFrame in our code, we are creating an *instance* of this class (what's known as instantiating a class). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Classes have **methods** and **attributes**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Methods** are functions belonging to the class.   \n",
    "\n",
    "- these functions perform actions on the dataframe or series\n",
    "- parentheses () can hold additional arguments\n",
    "\n",
    "Pandas example: `.sample()` - random sample of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Attributes** are properties of the class.  \n",
    "\n",
    "- these attributes are intrinsic to the dataframe or series\n",
    "- used for description\n",
    "\n",
    "Pandas example: `.columns` - column names of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For more information, view the [full list of DataFrame attributes and methods](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Try 4 or 5 of the attributes and methods listed to explore our temperatures dataset <code>df</code> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Syntax | Description |\n",
    "| :----------- | :----------- |\n",
    "| **.head()** | returns first 5 rows [default, put desired number of rows in the parentheses] |\n",
    "| **.tail()** | returns last 5 rows [default, put desired number of rows in the parentheses] |\n",
    "| **.sample()** | returns random sample of the dataframe |\n",
    "| **.dtypes** | returns data type of each column |\n",
    "| **.shape** | returns tuple representing the dimensionality of the dataframe (rows, columns) |\n",
    "| **.axes** | returns list representing axes of the dataframe |\n",
    "| **.info** | prints a summary of the dataframe |\n",
    "| **.columns** | returns column names |\n",
    "| **.unique()** | returns unique values for a given column or Series. *Note*: Must use this function on an individual column in a DataFrame, or on a singular Series |\n",
    "| **.describe()** | returns summary statistics for numeric columns |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Try 4 or 5 of the above functions to explore our temperatures dataset df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 5: Subsetting a DataFrame\n",
    "What if we want to search our dataframe for the temperature on a specific day? Or find all days with a specific temperature value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Option 1: Extract specific rows by index</div>   \n",
    "\n",
    "- **.iloc[ ]** - integer location; returns row at given integer\n",
    "- **.loc[ ]** - location; returns all rows with given index value; does not need to be an integer     \n",
    "\n",
    "We use the square bracket [ ] notation to select an index, just as we would when indexing strings or lists in other Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Look for the information at index 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for information at index 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# get multiple locations by indicating a range for our index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`.iloc[]` and `.loc[]` are great for subsetting our data, but we may not always know the indices we want to subset. More often, we'll be looking to subset our data based on certain *conditions*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    Option 2: Filter by known element in `days` column</div>   \n",
    "\n",
    "1. Select a column using `df.colName` or `df[column name]`\n",
    "2. Filter that column using [comparison and logical operators](https://www.w3schools.com/python/python_operators.asp) (examples: >, <, ==, |, &)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Filter <code>df</code> to show all rows where the <code>days</code> column is Tuesday </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# show all rows where days == Tuesday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# show all rows where days == Tuesday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Both of these syntax approaches return a Series of boolean values of `True` or `False`.  \n",
    "To return a subset, similar to what we did earlier with `.loc[]` and `.iloc[]`, we need to put our comparison statement in `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a subset of the dataframe where days == Tuesday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Filter <code>df</code> to show where the <code>days</code> column is Tuesday or Wednesday </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Filter <code>df</code> to return a <b>subset</b> of rows where the <code>days</code> column is Tuesday or Wednesday </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Filter <code>df</code> to return a <b>subset</b> of rows where the <code>temps_f</code> column is greater than 60 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Filter <code>df</code> to return a <b>subset</b> of rows where <code>days</code> is Saturday or Sunday, and <code>temps_f</code> is greater than 55 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Resource:** [Learn more about the indexing operator and how to select subsets of dataframes](https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    Option 3: Set `days` as the index, extract rows by index</div> \n",
    "    \n",
    "We can set one of the dataframe columns as the index using the **.set_index()** function   \n",
    "We can then use **.loc[ ]** to index the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the original dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe\n",
    "# use .set_index() to set the index to the 'days' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that now, our dataframe has the days as the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# explore the new dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why do this? Remember `.loc[]`?\n",
    "\n",
    "**.loc[ ]** - returns all rows with given index value; does not need to be an integer     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return rows where the index value is 'Tuesday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice how now you'll get an error if you search for index 0 using .loc[] but you CAN use .iloc[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6: Adding and renaming columns\n",
    "The temperature data we have are the high temps for the week. Let's add a new column with the week's low temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "low_temp_list = [41, 43, 45, 43, 54, 43, 37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the syntax to add a new column: `dataframe[col_name] = data_for_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column from low_temp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's change the name of column `temps_f` to the more descriptive `high_temps`   \n",
    "\n",
    "We have 2 options: we can use the **.rename()** method or the **columns** attribute\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) for .rename()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    To use the .rename() method, we provide a dictionary with <code>'old_column_name' : 'new_column_name'</code><br>Remember that Python dictionaries use <code>{}</code> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a python dictionary where the key = current column name, value = new column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To use the columns attribute, simply provide a list of all of the column names you want for the dataframe. This is a great option if you are renaming multiple columns. But, you must provide a name for **all** of the columns in the dataframe, even if you do not want to change all of the column names.   \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Use the <code>columns</code> attribute to change all of the column names to uppercase: </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by listing all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5 minute break\n",
    "When we come back: Penguins!\n",
    "\n",
    "![Gentoo penguin with chick](Images/Gentoo_Penguin_with_chick_at_Jougla_Point,_Antarctica_(6063647060).jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h3>Section 2: Palmer Penguins dataset</h3>\n",
    "    <h4>In this section:</h4>\n",
    "    \n",
    "[More data manipulation](#More-data-manipulation)   \n",
    "[Exercise 7: Exploratory data analysis](#Exercise-7:-Exploratory-data-analysis)   \n",
    "[Exercise 8: Dealing with missing values](#Exercise-8:-Dealing-with-missing-values)   \n",
    "[Exercise 9: Sorting data](#Exercise-9:-Sorting-data) \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More data manipulation\n",
    "In this section, we'll use the Palmer Penguins dataset. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\n",
    "\n",
    "This dataset was compiled by developer Allison Horst as an R package [(see R documentation here)](https://allisonhorst.github.io/palmerpenguins/).   \n",
    "\n",
    "The dataset is also available as a [Python library](https://pypi.org/project/palmerpenguins/), which I have converted to a CSV file and provided for this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this section, we will:\n",
    "- Import data from a CSV file\n",
    "- Perform exploratory data analysis\n",
    "- Clean and manipulate the dataset\n",
    "    - Handle missing values\n",
    "    - Sort the dataset  \n",
    "    - Calculate basic summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Use the <code>.read_csv()</code> method to import our dataset.\n",
    "    </div>\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for .read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import the dataset from file palmerpenguins.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 7: Exploratory data analysis\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Spend 2 minutes getting to know the <code>penguins</code> dataset. Try methods and attributes like .shape, .dtypes, .describe(), or .unique()\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 8: Dealing with missing values\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    We'll use the <code>.isna()</code> method to check if we have any missing values (NaN) in our dataset. Then we will drop all rows that have any missing value using <code>.dropna()</code>\n",
    "    </div>\n",
    "\n",
    "- [Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) for .isna()   \n",
    "- [Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) for .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`.isna()` will also work with a specific column: `df[column].isna()`   \n",
    "You can add the `.unique()` function to quickly see if any data is the column is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .isna() and .unique() together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**.dropna()** will drop rows or columns that have missing values.  \n",
    "The `axis` argument is EXTREMELY important!\n",
    "- `axis=0` -- drop rows with missing values\n",
    "- `axis=1` -- drop columns with missing values\n",
    "\n",
    "Read more [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows that have at least one missing value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our dataset started with 344 rows. After dropping rows with missing values, how many rows are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# check size of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now have 333 rows. We still have all 8 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can check for missing values again in, for example, the `bill_length_mm` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 9: Sorting data \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Use <code>.sort_values()</code> to order <code>penguins</code> by bill length, from smallest to largest. Then order <code>penguins</code> by bill length from largest to smallest.  \n",
    "    </div>\n",
    "\n",
    "By default, the **.sort_values()** method sorts data in ascending order (smallest to largest).  \n",
    "- Use the `by` argument to specify which column(s) to sort\n",
    "- Use the `ascending=False` argument to sort in descending order\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) for .sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# sort penguins by bill length, smallest to largest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# sort penguins by bill length, largest to smallest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can sort a dataframe by multiple variables by passing a list of column names into the `by` argument.   \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Sort <code>penguins</code> first by year, then by bill length in ascending order (smallest to largest).\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort penguins by year, then bill length in ascending order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also specify ascending vs descending order for each column when sorting by multiple columns by passing a second list for our `ascending` argument. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Sort <code>penguins</code> first by year in descending order, then by bill length in ascending order.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort penguins by year (descending order), then bill length (ascending order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Resource**: for more examples of sorting mechanisms in pandas, see [this article](https://www.geeksforgeeks.org/how-to-sort-a-pandas-dataframe-by-multiple-columns-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "Today we covered:\n",
    "- what is `pandas`?\n",
    "- Data Structures: pandas Series and DataFrames\n",
    "- Creating and exploring a Series object\n",
    "- Creating and exploring a DataFrame object\n",
    "    - subsetting \n",
    "    - adding and renaming columns\n",
    "- Data manipulation:\n",
    "    - exploratory data analysis\n",
    "    - removing missing values (`NaN`)\n",
    "    - sorting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stay tuned for Part 2:\n",
    "We'll cover:\n",
    "- Data manipulation continued:\n",
    "    - grouping and aggregating data\n",
    "    - joining data\n",
    "- Further data exploration:\n",
    "    - basic calculations\n",
    "- Exporting a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "March 6, 2023 from 1-3 pm.  \n",
    "Same Zoom link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?   \n",
    "\n",
    "## Contact us at dataservices@jhu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### About this Presentation  \n",
    "This presentation was created using Jupyter Notebooks version 6.5.2 and the RISE notebook extension version 5.7.1.    \n",
    "\n",
    "### Terms of Use \n",
    "The presentation materials are licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/), attributable to Data Services, Johns Hopkins University.   \n",
    "\n",
    "Please cite this material as:\n",
    "\n",
    "> Johns Hopkins University Data Services. (2023, February 27). Data Wrangling in Python: Introduction to the pandas library [workshop presentation]."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
