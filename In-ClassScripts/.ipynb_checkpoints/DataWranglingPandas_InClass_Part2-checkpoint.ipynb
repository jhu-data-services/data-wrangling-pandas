{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Wrangling in Python\n",
    "## Introduction to the pandas library, part 2\n",
    "### [dataservices.library.jhu.edu](https://dataservices.library.jhu.edu/)\n",
    "#### Reina Chano Murray, JHU Data Services\n",
    "#### Date: March 6, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### Introduction\n",
    "[Software and materials](#Software-and-materials)   \n",
    "[About this Webinar](#About-this-Webinar)   \n",
    "[Learning objectives](#Learning-Objectives)   \n",
    "\n",
    "#### Section 2: Palmer Penguins dataset continued\n",
    "[Exploratory Data Analysis Continued](#Exploratory-Data-Analysis-Continued)   \n",
    "[Exercise 7: Exploratory data analysis](#Exercise-7:-Exploratory-data-analysis)   \n",
    "[Exercise 8: Dealing with missing values](#Exercise-8:-Dealing-with-missing-values)   \n",
    "[Exercise 9: Sorting data](#Exercise-9:-Sorting-data)    \n",
    "[Exercise 10: Quick Refresh](#Exercise-10:-Quick-Refresh---Explore-the-Dataset)  \n",
    "[Exercise 11: Basic Calculations](#Exercise-11:-Basic-calculations)  \n",
    "[Exercise 12: Grouping and aggregating data](#Exercise-12:-Grouping-and-aggregating-data)  \n",
    "\n",
    "#### Section 3: Most Populous Cities\n",
    "[Combining Data](#Combining-Data)   \n",
    "[Exercise 13: Concatenate Data](#Exercise-13:-Concatenate-Data)   \n",
    "[Exercise 14: Merge Data](#Exercise-14:-Merge-Data)   \n",
    "[Exercise 15: Join Data](#Exercise-15:-Join-Data)   \n",
    "[Exercise 16: Basic Calculations](#Exercise-16:-Basic-Calculations)  \n",
    "[Exercise 17: Export Table](#Exercise-17:-Export-Table) \n",
    "\n",
    "#### Resources section \n",
    "[Resources](#Resources)   \n",
    "[Questions?](#Questions?)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Software and materials     \n",
    "\n",
    "- Jupyter Notebooks or JupyterLab ([Anaconda distribution](https://www.anaconda.com/products/individual) recommended)   \n",
    "    - Please install the following libraries:\n",
    "        - `pandas`\n",
    "- Zip folder from the Data Service [github repo](https://github.com/jhu-data-services/data-wrangling-pandas) containing:\n",
    "    - DataWranglingPandas_InClass.ipynb\n",
    "    - Images folder\n",
    "    - Data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this Webinar\n",
    "\n",
    "#### Recording\n",
    "This workshop will be recorded. Recording will be stopped during Q&A. An edited version of this recording will be made available for JHU patrons to access via Panopto later in the semester. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 2-part series\n",
    "Today is part 2 of our 2 part series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "<div class=\"alert alert-info\">\n",
    "    <p>Over the course of this 2-part webinar series, students will learn:\n",
    "        <ul>\n",
    "            <li>what the pandas library is</li>\n",
    "            <li>the two primary data structures of the pandas library: Series and DataFrame</li>\n",
    "            <li>How to implement functions from the pandas library to explore and manipulate a dataset, including:\n",
    "                <ul>\n",
    "                    <li>Exploratory data analysis</li>\n",
    "                    <li>Subsetting or filtering data</li>\n",
    "                    <li>Handling missing data</li>\n",
    "                    <li>Sorting data</li>\n",
    "                    <li>Calculating basic summary statistics</li>\n",
    "                    <li>Grouping data</li>\n",
    "                    <li>Joining data</li>\n",
    "                </ul></li>\n",
    "            <li>How to review documentation and reference information for pandas</li>\n",
    "         </ul>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='./Images/DataServicesAbout.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Note: the copy of these materials you have downloaded is YOURS\n",
    "\n",
    "Add notes, write additional code or comments, mark up the document in a way that is helpful to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Section 2 continued\n",
    "Wrapping up data manipulations -- with penguins!\n",
    "![Gentoo penguin with chick](Images/Gentoo_Penguin_with_chick_at_Jougla_Point,_Antarctica_(6063647060).jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h3>Section 2 continued: Palmer Penguins dataset</h3>\n",
    "    <h4>In this section:</h4>\n",
    "    \n",
    "[Exploratory Data Analysis Continued](#Exploratory-Data-Analysis-Continued)   \n",
    "[Exercise 7: Exploratory data analysis](#Exercise-7:-Exploratory-data-analysis)   \n",
    "[Exercise 8: Dealing with missing values](#Exercise-8:-Dealing-with-missing-values)   \n",
    "[Exercise 9: Sorting data](#Exercise-9:-Sorting-data)    \n",
    "[Exercise 10: Quick Refresh](#Exercise-10:-Quick-Refresh---Explore-the-Dataset)  \n",
    "[Exercise 11: Basic Calculations](#Exercise-11:-Basic-calculations)  \n",
    "[Exercise 12: Grouping and aggregating data](#Exercise-12:-Grouping-and-aggregating-data)\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploratory Data Analysis Continued\n",
    "We'll continue using the Palmer Penguins dataset. \n",
    "\n",
    "Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\n",
    "\n",
    "This dataset was compiled by developer Allison Horst as an R package [(see R documentation here)](https://allisonhorst.github.io/palmerpenguins/).   \n",
    "\n",
    "The dataset is also available as a [Python library](https://pypi.org/project/palmerpenguins/), which I have converted to a CSV file and provided for this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this section, we will:\n",
    "- Import data from a CSV file\n",
    "- Run basic calculations/summary statistics\n",
    "- Group and aggregate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Review</b>: We'll start by importing the <code>pandas</code> library and reading in our csv file. Use the <code>.read_csv()</code> method to import our dataset.\n",
    "    </div>\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for .read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas (as pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import the dataset from file palmerpenguins.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 10: Quick Refresh - Explore the Dataset  \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Let's start by re-familiarizing ourselves with the penguins dataset. Use methods like `.shape`, `.dtypes`, `.sample()`, `.describe()` and `.unique()` to take a look at the dataset.\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns does the dataset have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What measurements are taken for each penguin? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What islands are the penguins from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 11: Basic calculations  \n",
    "\n",
    "The pandas library includes computational tools to analyze a dataframe. These can give us summary statistics like **.mean()** or **.median()**, or more advanced statistics like correlation (**.corr()**)\n",
    "\n",
    "[More on computation](https://pandas.pydata.org/docs/user_guide/computation.html) in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Find the mean value for each of the numeric variables, the median value for <code>bill_depth_mm</code> and the correlation between numeric variables.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# calculate mean of each numeric variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate median of bill_depth_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 12: Grouping and aggregating data\n",
    "\n",
    "The `.groupby()` function separates a dataframe into groups based on the dataframe's columns. This function uses a split-apply-combine process:   \n",
    "- Splitting the data into groups based on some criteria\n",
    "- Applying a function to each group independently\n",
    "- Combining the results into a data structure   \n",
    "\n",
    "The .groupby() function keeps track of which rows of the dataframe belong to each group. The function returns a GroupBy object that is not very informative on its own. We can see what is inside of a GroupBy object by adding additional methods like `.get_group()`, `.groups`, or `.size()`.  We can also aggregate data within groups by adding methods like `.sum()` or `.mean()`.   \n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/groupby.html) for .groupby()   \n",
    "\n",
    "[More on the split-apply-combine process](https://pandas.pydata.org/docs/user_guide/groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    See what gets returned when you group penguins by <code>species</code>.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We're returned a description of a GroupBy object (a pandas class), and where it sits in our memory. To extract more information, we'll need to chain other methods like `.size()` or `.count()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Understanding the difference between `.size()` and `.count()`\n",
    "Both methods are common ways to quickly aggregate and count the number of rows in each group after applying `.groupby`. However, these two methods can differ in results if you have missing values in your dataset. Let's see this in action. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Use <code>.size()</code> to group penguins by <code>species</code>.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Use <code>.count()</code> to group penguins by <code>species</code>.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do these numbers mean? Why do some of the numbers across the rows differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The DataFrame shows us the **count** across all columns in our dataset. If an entry had a missing value, a `NaN`, in a column, it is not included in this tally. Last week, we removed any rows that had missing values; we didn't take that step this time around.  \n",
    "\n",
    "`.size()` operates like `len()` -- it counts the total number of rows for each group. It is not affected by `NaN` values. \n",
    "\n",
    "`.count()` however, returns the number of **values** in each group, which may or may not be equal to the number of rows because any `NaN` values encountered by the count() method. \n",
    "\n",
    "What about other methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Group penguins by <code>species</code>. Then calculate the <b>mean</b> for <code>flipper_length_mm</code>.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.mean.html) for `.GroupBy.mean`. \n",
    "\n",
    "The description notes that missing values are excluded. Keep this in mind when you use `.GroupBy.mean` -- whether you remove your missing values from your dataset is up to you, just make sure you document your workflow and reasoning clearly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Group penguins by <code>species</code> and <code>island</code>. <b>Get a count of how many penguins of each species were on each island.</b>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's explore one more powerful method: **aggregate**. \n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html)  \n",
    "[Resource](https://towardsdatascience.com/all-about-pandas-groupby-explained-with-25-examples-494e04a8ef56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Group penguins by <code>species</code> and <code>sex</code>. <b>Calculate the mean, min and max for <code>body_mass_g</code><b>. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Let's up this exercise a notch. <br>Create a new DataFrame of just entries for <b>Adelie</b> penguins. Create a summary table with the number of observations, average <code>body_mass_g</code>, max <code>flipper_length_mm</code>, and min <code>bill_depth_mm</code> for each <code>sex</code>. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Fun tip</b>: to round your numbers, chain on <code>.round(n)</code>, making sure to specify how many places to round to. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5 minute break\n",
    "When we come back: joining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h3>Section 3: Most Populous Cities</h3>\n",
    "    <h4>In this section:</h4>\n",
    "    \n",
    "[Combining Data](#Combining-Data)   \n",
    "[Exercise 13: Concatenate Data](#Exercise-13:-Concatenate-Data)   \n",
    "[Exercise 14: Merge Data](#Exercise-14:-Merge-Data)   \n",
    "[Exercise 15: Join Data](#Exercise-15:-Join-Data)   \n",
    "[Exercise 16: Basic Calculations](#Exercise-16:-Basic-Calculations)  \n",
    "[Exercise 17: Export Table](#Exercise-17:-Export-Table) \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining Data\n",
    "It's not unusual to have our data spread across multiple tables. We often want to join or merge our data together in a single place to begin our analysis. \n",
    "\n",
    "We'll now look at 3 approaches to combining data in pandas: `concat()`, `merge()` and `.join()`. We'll use 3 spreadsheets, *citiestop20.csv*, *citiestop21_40.csv*, and *citiespop23.csv*, which were prepared for this webinar by downloading and manipulating data available at [World Population Review](https://worldpopulationreview.com/world-cities). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 13: Concatenate Data\n",
    "The `concat()` function in pandas allows us to append either columns or rows from one DataFrame to another. The `axis` argument determines whether we 'stack' two DataFrames on top of each other or side by side.  \n",
    "\n",
    "`axis=0` refers to the *rows* of the DataFrames, and tells pandas to stack the DataFrames vertically. `axis=1` refers to the *columns* of the DataFrames and tells pandas to stack the DataFrames horizontally. \n",
    "\n",
    "When stacking vertically, make sure the two DataFrames have the same columns and respective data types. When stacking horizontally, make sure your data is related in a way that makes sense. \n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Read in <b>citiestop20.csv</b> and <b>citiestop21_40.csv</b> as separate DataFrames. These two tables are from the same dataset; one shows the top 20 most populous cities, and the other the most populous cities ranked 21 to 40. Examine the two DataFrames. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets citiestop20.csv and citiestop21_40.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Use <code>concat()</code> to stack the two DataFrames vertically into a new DataFrame, <b>top40cities</b>.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame top40cities by using concat() and vertically stacking together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Fun tip</b>: to reset the index, either run <code>.reset_index(drop=True)</code> on your new DataFrame, or use the <code>ignore_index=True</code> argument when running <code>concat()</code>.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 14: Merge Data\n",
    "`merge()` operates like a database's join operations, and is the most flexible function of the three approaches to combining data. `merge()` is most useful when you want to combine rows that share data. Both **many-to-one** and **one-to-many** joins can be achieved with `merge()`. \n",
    "\n",
    "Like with a database's join operations, you need to specify both the *left* and *right* DataFrames or Series to join together. Optional arguments include:\n",
    "- *how* -- defines the type of merge to make. Default is 'inner', but 'outer', 'left', and 'right' joins are possible. \n",
    "- *on* -- defines which columns or indices to join on\n",
    "- *left_on* and *right-on* -- specify a column or index present only in the left or right object that you are merging. \n",
    "\n",
    "See [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) for more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Read in <b>citiespop23.csv</b> as a DataFrame. This table contains stats for the top 40 populous cities' 2023 population.  \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset citiespop23.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Create a new DataFrame, <b>cities_pop22_23</b> by using <code>merge()</code> to combine DataFrames <b>top40cities</b> and <b>citiespop23</b> using the <b>city</b> columns.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 15: Join Data\n",
    "`.join()` is similar to `merge()`, but it is a method specific to the DataFrame class. We call it on a DataFrame. \n",
    "\n",
    "The other key difference between `.join()` and `merge()` is that `.join()` combines two DataFrames on the basis of their indices, whereas `merge()` allows us to specify columns to perform a join on. `merge()` therefore provides more flexibility; manipulating `.join()` requires setting indices using the `.set_index()` method to set your indices to the key columns you want to join on. \n",
    "\n",
    "See [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) for more information.  \n",
    "See [this article](https://realpython.com/pandas-merge-join-and-concat/#pandas-join-combining-data-on-a-column-or-index) for a detailed explanation of how `.join()` works on indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Example</b>: performing a <code>.join()</code> on <b>top40cities</b> with <b>citiespop23</b>.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "top40cities_join_demo = top40cities.set_index(['city', 'country'])\n",
    "top40cities_join_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top40cities_join_demo = top40cities_join_demo.join(\n",
    "    citiespop23.set_index(['city', 'country']), \n",
    "    on = ['city', 'country'],\n",
    "    how = 'inner'\n",
    ")\n",
    "top40cities_join_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 16: Basic Calculations\n",
    "Our very first exercise in this workshop was exploring how a simple calculation to convert temperatures from F to C could be done with fewer lines of code using a pandas Series. \n",
    "\n",
    "Let's now add a new column to our DataFrame **cities_pop22_23**, that calculates the percent change in population from 2022 to 2023 for each city. \n",
    "\n",
    "We'll use this syntax to add a new column and run this calculation:\n",
    "`df[column name] = calculation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Add column <b>pct_change</b> to the <b>cities_pop22_23</b> DataFrame and calculate percent change in population from 2022 to 2023.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column pct change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 17: Export Table\n",
    "Let's end our webinar today by exporting our final results to a csv. To do so, use the pandas function `to_csv()`. \n",
    "\n",
    "To remove the index, use argument `index = False`.\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Export DataFrame <b>cities_pop22_23</b> to your Desktop.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__pandas Resources__   \n",
    "[pandas Official Documentation](https://pandas.pydata.org/pandas-docs/stable/)   \n",
    "[pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html)   \n",
    "[Comparing pandas to R programming](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html)   \n",
    "Comparing pandas to [Excel](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_spreadsheets.html), [SQL](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html), [SAS](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sas.html), and [Stata](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_stata.html)   \n",
    "\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/) - contains articles on Python and other programming languages, from beginner to expert levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__A few more things pandas can do:__   \n",
    "Pivot tables and reshaping datasets - [blog post with images](https://nikgrozev.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/), [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)   \n",
    "\n",
    "Merging, joining and comparing datasets - [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html), [.join() function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html), [tutorial with images](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/08_combine_dataframes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Jupyter Notebooks Resources__   \n",
    "[Project Jupyter](https://jupyter.org/) - organization behind Jupyter Notebooks   \n",
    "[Anaconda](https://www.anaconda.com/) - environment manager and GUI for launching Jupyter Notebooks  \n",
    "[RISE slideshow extension for Jupyter Notebooks](https://rise.readthedocs.io/en/stable/)   \n",
    "[Guide to interactive notebooks](https://morphocode.com/interactive-notebooks-data-analysis-visualization/)   \n",
    "[Programming Historian: Introduction to Jupyter Notebooks](https://programminghistorian.org/en/lessons/jupyter-notebooks)   \n",
    "[Basic Markdown syntax](https://www.markdownguide.org/basic-syntax) for formatting text elements   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Conferences__   \n",
    "[Pycon 2022](https://us.pycon.org/2022/) - annual Python users conference, past talks [available on Youtube](https://www.youtube.com/channel/UCMjMBMGt0WJQLeluw6qNJuA)     \n",
    "[PyData conferences and meetups](https://pydata.org/)   \n",
    "[SciPy conference](http://conference.scipy.org/)   \n",
    "[More Python community events](https://www.python.org/community/workshops/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>SciServer from JHU Institute for Data Intensive Engineering and Sciences (IDIES)</b>\n",
    "<br><br>\n",
    "\n",
    "![sciserver-logo](./Images/sciserverlogo.png)\n",
    "\n",
    "\n",
    "SciServer is a fully integrated, collaborative science platform with analysis tools and hosted datasets (i.e. no need for downloads). It’s free for anyone, anywhere to use!   \n",
    "\n",
    "Why use SciServer?\n",
    "- Provides 2.5+PB of free hosted datasets including Sloan Digital Sky Survey Spectroscopic Data, Johns Hopkins Ocean Circulation Models, and more!\n",
    "- Facilitates collaborative research and knowledge sharing.\n",
    "- Utilizes Jupyter Notebooks in Python, R, Julia, and MATLAB for reproducible results.\n",
    "- Allows you to leverage compute power far beyond that of your personal machine.   \n",
    "\n",
    "\n",
    "<b>Access SciServer and learn more:</b>\n",
    "\n",
    "- [www.sciserver.org/support/how-to-use-sciserver](https://www.sciserver.org/support/how-to-use-sciserver/) — How to log in to SciServer\n",
    "- [apps.sciserver.org/login-portal](https://apps.sciserver.org/login-portal/) — Access SciServer\n",
    "- [www.sciserver.org](https://www.sciserver.org/) — Informational website\n",
    "- [www.sciserver.org/support](https://www.sciserver.org/support/) — Instructions for getting started (including video tutorials for setting up an account  and a comprehensive instructional PDF)\n",
    "- [www.idies.jhu.edu](https://www.idies.jhu.edu/) — Information about JHU’s Institute for Data Intensive Engineering and Science (IDIES), architect and administrator of SciServer, and a resource for working with large datasets   \n",
    "\n",
    "<b>Course Examples using SciServer:</b>   \n",
    "- [Astronomy 101](https://github.com/ritatojeiro/SDSSEPO) taught by Rita Tojeiro, University of St Andrews\n",
    "- [Upper-level Astronomy](https://github.com/brittlundgren/SDSS-EPO) taught by Britt Lundgren, University of North Carolina Asheville  \n",
    "\n",
    "\n",
    "SciServer is operated by the Institute for Data Intensive Engineering and Science—a partnership of Sheridan Libraries, Bloomberg School of Public Health, Carey Business School, Krieger School of Arts and Sciences, School of Medicine, and Whiting School of Engineering—and funded by National Science Foundation.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other JHU Data Services Webinars\n",
    "See our [Calendar](https://dataservices.library.jhu.edu/training-workshops/calendar/) for future events. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h3>Take our survey to help us improve this workshop:</h3>\n",
    "    <h3><a href=https://www.surveymonkey.com/r/IntroPandas>https://www.surveymonkey.com/r/IntroPandas</a></h3>\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?   \n",
    "\n",
    "## Contact us at dataservices@jhu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### About this Presentation  \n",
    "This presentation was created using Jupyter Notebooks version 6.5.2 and the RISE notebook extension version 5.7.1.    \n",
    "\n",
    "### Terms of Use \n",
    "The presentation materials are licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/), attributable to Data Services, Johns Hopkins University.   \n",
    "\n",
    "Please cite this material as:\n",
    "\n",
    "> Johns Hopkins University Data Services. (2023, February 27). Data Wrangling in Python: Introduction to the pandas library [workshop presentation]."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
