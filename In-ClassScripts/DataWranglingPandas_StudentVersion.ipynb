{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Wrangling in Python: Introduction to the pandas library\n",
    "## [dataservices.library.jhu.edu](https://dataservices.library.jhu.edu/)\n",
    "### Marley Kalt and Harshil Desai, JHU Data Services\n",
    "### Date: November 9, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### Introduction\n",
    "[Software and materials](#Software-and-materials)   \n",
    "[Pre-requisites](#Pre-requisites)   \n",
    "[Learning objectives](#Today,-you-will-learn:)   \n",
    "\n",
    "#### Section 1: Temperatures dataset\n",
    "[pandas Overview](#pandas:-a-Python-library-for-data-analysis)   \n",
    "[Exercise 1: Why use pandas?](#Exercise-1:-Why-use-pandas?)   \n",
    "[Data structures: Series and DataFrame](#Data-structures:-Series-and-DataFrame)   \n",
    "[pandas Series](#pandas-Series)   \n",
    "[Exercise 2: Create a Series object](#Exercise-2:-Create-a-Series-object)   \n",
    "[pandas DataFrame](#pandas-DataFrame)   \n",
    "[Exercise 3: Create a DataFrame](#Exercise-3:-Create-a-DataFrame)   \n",
    "[Exercise 4: Exploring a DataFrame](#Exercise-4:-Exploring-a-DataFrame)   \n",
    "[Exercise 5: Subsetting a DataFrame](#Exercise-5:-Subsetting-a-DataFrame)   \n",
    "[Exercise 6: Adding and renaming columns](#Exercise-6:-Adding-and-renaming-columns)   \n",
    "\n",
    "#### Section 2: Palmer Penguins dataset\n",
    "[More data manipulation](#More-data-manipulation)   \n",
    "[Exercise 7: Exploratory data analysis](#Exercise-7:-Exploratory-data-analysis)   \n",
    "[Exercise 8: Dealing with missing values](#Exercise-8:-Dealing-with-missing-values)   \n",
    "[Exercise 9: Sorting data](#Exercise-9:-Sorting-data)   \n",
    "[Exercise 10: Basic calculations](#Exercise-10:-Basic-calculations)   \n",
    "[Exercise 11: Grouping and aggregating data](#Exercise-11:-Grouping-and-aggregating-data)   \n",
    "\n",
    "#### Resources section\n",
    "[Additional Practice](#Additional-Practice)   \n",
    "[Resources](#Resources)   \n",
    "[Questions?](#Questions?)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Software and materials     \n",
    "\n",
    "- Jupyter Notebooks or JupyterLab ([Anaconda distribution](https://www.anaconda.com/products/individual) recommended)   \n",
    "- pandas library installed\n",
    "- Zip folder containing:\n",
    "    - DataWranglingPandas_Workshop.ipynb\n",
    "    - Images folder\n",
    "    - Data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pre-requisites:\n",
    "\n",
    "- Knowledge of basic programming concepts\n",
    "    - Data types\n",
    "    - Variable assignment\n",
    "    - Function calls\n",
    "- Introductory experience in Python or R (like Data Services' Intro to Python or Intro to R workshops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This workshop will not be recorded  \n",
    "\n",
    "You will receive all workshop materials by tomorrow afternoon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='./Images/DataServicesAbout.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today, you will learn:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The two primary data structures of the pandas library: Series and DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How to implement functions from the pandas library to explore and manipulate a dataset, including:  \n",
    "    - Exploratory data analysis\n",
    "    - Subsetting or filtering data\n",
    "    - Handling missing data  \n",
    "    - Sorting data  \n",
    "    - Grouping data  \n",
    "    - Calculating basic summary statistics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='./Images/pandas-logo.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Section 1: Temperatures dataset\n",
    "#### In this section:\n",
    "[pandas Overview](#pandas:-a-Python-library-for-data-analysis)   \n",
    "[Exercise 1: Why use pandas?](#Exercise-1:-Why-use-pandas?)   \n",
    "[Data structures: Series and DataFrame](#Data-structures:-Series-and-DataFrame)   \n",
    "[pandas Series](#pandas-Series)   \n",
    "[Exercise 2: Create a Series object](#Exercise-2:-Create-a-Series-object)   \n",
    "[pandas DataFrame](#pandas-DataFrame)   \n",
    "[Exercise 3: Create a DataFrame](#Exercise-3:-Create-a-DataFrame)   \n",
    "[Exercise 4: Exploring a DataFrame](#Exercise-4:-Exploring-a-DataFrame)   \n",
    "[Exercise 5: Subsetting a DataFrame](#Exercise-5:-Subsetting-a-DataFrame)   \n",
    "[Exercise 6: Adding and renaming columns](#Exercise-6:-Adding-and-renaming-columns)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pandas: a Python library for data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Supports data manipulation and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Works with tabular data (spreadsheets, databases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Similar structure to R programming language (DataFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Especially good for time series data, statistics, machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Documentation: [https://pandas.pydata.org/docs/index.html](https://pandas.pydata.org/docs/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 1: Why use pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of temperatures in Fahrenheit. In an empty code cell, write some Python code to convert the temperatures from Fahrenheit to Celsius. Assign the new temperatures to a new list called `temps_c`   \n",
    "\n",
    "The formula to convert Fahrenheit to Celsius is\n",
    "$${\\frac {F-32}{1.8}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_f = [66, 70, 66, 64, 64, 59, 52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to convert temps_f to Celsius\n",
    "temps_c = []\n",
    "for temp in temps_f:\n",
    "    celsius = (temp - 32) / 1.8\n",
    "    temps_c.append(celsius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data structures: Series and DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A one-dimensional array\n",
    "    - Similar to a spreadsheet with 1 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Can hold any data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Row (axis) labels are called the **index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2: Create a Series object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pandas Series using our list of temperatures in Fahrenheit, `temps_f`, and use the pandas library to convert the temperatures to Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform list temps_f into a pandas series named temps_series_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_series_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `temps_series_f`, the left column (0, 1, 2, 3,...) is the index. The right column (66, 70, 66...) is our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Fahrenheit values in temp_series_f to Celsius, saved in a variable named temp_series_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_series_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A two-dimensional array\n",
    "    - Similar to a spreadsheet with multiple columns, or many Series combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Can hold any data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Row (axis 0) labels are called the index\n",
    "- Column (axis 1) labels are called columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3: Create a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe, called `df`, using our list of temperatures, `temps_f`, and the below list of days of the week, `days`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways we can create a dataframe from scratch. Below are two possibilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1: Create an empty DataFrame, then add our lists as new columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe named df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax to add a new column is `dataframe[col_name] = data_for_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column temps_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: Combine our two lists into a Python dictionary, then create a DataFrame from the dictionary**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine days and temps_f into a Python dictionary\n",
    "temp_dict = {'Days': days, 'Temps_F': temps_f}\n",
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame from dictionary object\n",
    "df_fromDict = pd.DataFrame(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe\n",
    "df_fromDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5 minute break\n",
    "When we come back: Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4: Exploring a DataFrame\n",
    "In this section, we will find basic information about our dataframe and start to manipulate our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "pandas has several functions to help us explore a new dataset:\n",
    "- **.head()** - first 5 rows [default, put desired number of rows in the parentheses]\n",
    "- **.tail()** - last 5 rows [default, put desired number of rows in the parentheses]\n",
    "- **.sample()** - random sample of the dataframe\n",
    "- **.dtypes** -  data type of each column\n",
    "- **.shape** - tuple of (rows, columns)\n",
    "- **len()** - base Python function, length of object\n",
    "    - Note: In the pandas functions, we put our data object first, `df.function_name`, as required by pandas syntax. In contrast, `len()` is a Python function and uses different syntax.\n",
    "- **.columns** - column names\n",
    "- **.unique()** - unique values for a given column or Series\n",
    "    - Must use this function on an individual column in a DataFrame, or on a singular Series\n",
    "- **.describe()** - summary statistics for numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why do some of these functions have parentheses and some do not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Functions with () are **methods**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Functions without () are **attributes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Methods:\n",
    "- Actions performed on a dataframe\n",
    "- Parentheses () can hold additional arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Attributes:\n",
    "- Things intrinsic to the dataframe\n",
    "- Used for description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Resource:** [Full list of DataFrame attributes and methods](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try 4 or 5 of the above functions to explore our temperatures dataset, `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 5: Subsetting a DataFrame\n",
    "What if we want to search our dataframe for the temperature on a specific day? Or find all days with a specific temperature value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Option 1: Extract specific rows by index**\n",
    "- **.iloc[ ]** - integer location; returns row at given integer\n",
    "- **.loc[ ]** - location; returns all rows with given index value; does not need to be an integer     \n",
    "\n",
    "We use the square bracket [ ] notation to select an index, just as we would when indexing strings or lists in other Python programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Option 2: Filter by known element in `Days` column**\n",
    "\n",
    "1. Select a column using `df.colName` or `df[column name]`\n",
    "2. Filter that column using [comparison and logical operators](https://www.w3schools.com/python/python_operators.asp) (examples: >, <, ==, |, &)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Filter `df` to show all rows where the Days column is Tuesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter `df` to show all rows where the Days column is Tuesday or Wednesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter `df` to show all rows where the Temps_F column is greater than 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter `df` to show all rows where Days is Saturday or Sunday, and Temps_F is greater than 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resource:** [Learn more about the indexing operator and how to select subests of dataframes, here](https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Option 3: Set `Days` as the index, extract rows by index**   \n",
    "\n",
    "We can set one of the dataframe columns as the index using the **.set_index()** function   \n",
    "We can then use **.loc[ ]** to index the dataframe  \n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html) for .set_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6: Adding and renaming columns\n",
    "The temperature data we have are the high temps for this week. Let's add a new column with this week's low temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "low_temp_list = [41, 43, 45, 43, 54, 43, 37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the syntax to add a new column: `dataframe[col_name] = data_for_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column from low_temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's change the name of column `Temps_F` to the more descriptive `High_Temps`   \n",
    "\n",
    "We can use the **.rename()** function or the **columns** attribute\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html) for .rename()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the .rename() function, we provide a dictionary with 'old_column_name' : 'new_column_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the columns function, simply provide a list of all of the column names you want for the dataframe. This is a great option if you are renaming multiple columns. But, you must provide a name for **all** of the columns in the dataframe, even if you do not want to change all of the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5 minute break\n",
    "When we come back: Penguins!\n",
    "\n",
    "![Gentoo penguin with chick](Images/Gentoo_Penguin_with_chick_at_Jougla_Point,_Antarctica_(6063647060).jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Section 2: Palmer Penguins dataset\n",
    "#### In this section:\n",
    "[More data manipulation](#More-data-manipulation)   \n",
    "[Exercise 7: Exploratory data analysis](#Exercise-7:-Exploratory-data-analysis)   \n",
    "[Exercise 8: Dealing with missing values](#Exercise-8:-Dealing-with-missing-values)   \n",
    "[Exercise 9: Sorting data](#Exercise-9:-Sorting-data)   \n",
    "[Exercise 10: Basic calculations](#Exercise-10:-Basic-calculations)   \n",
    "[Exercise 11: Grouping and aggregating data](#Exercise-11:-Grouping-and-aggregating-data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More data manipulation\n",
    "In this section, we'll use the Palmer Penguins dataset. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\n",
    "\n",
    "This dataset was compiled by developer Allison Horst as an R package [(see R documentation here)](https://allisonhorst.github.io/palmerpenguins/).   \n",
    "\n",
    "The dataset is also available as a [Python library](https://pypi.org/project/palmerpenguins/), which I have converted to a CSV file and provided for this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this section, we will:\n",
    "- Import data from a CSV file\n",
    "- Perform exploratory data analysis\n",
    "- Clean and manipulate the dataset\n",
    "    - Handle missing values\n",
    "    - Sort the dataset  \n",
    "    - Group the dataset in different ways  \n",
    "    - Calculate basic summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use the **.read_csv()** function to import our dataset.\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for .read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import the dataset from file palmerpenguins.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 7: Exploratory data analysis\n",
    "Spend 3 minutes getting to know the `penguins` dataset\n",
    "\n",
    "Try functions like .shape, .dtypes, .describe(), or .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 8: Dealing with missing values\n",
    "We'll use the **.isna()** function to check if we have any missing value (NaN) in our dataset. Then we will drop all rows that have any missing value using **.dropna()**    \n",
    "\n",
    "- [Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) for .isna()   \n",
    "- [Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) for .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.isna()` will also work with a specific column: `df[column].isna()`   \n",
    "You can add the `.unique()` function to quickly see if any data is the column is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .isna() and .unique() together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.dropna()** will drop rows or columns that have missing values.    \n",
    "Specify that we want to drop rows using the \"axis=0\" argument. If we wanted to drop columns with missing values, we would use \"axis=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows that have at least one missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset started with 344 rows. After dropping rows with missing values, we have 333 rows. We still have all 8 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 9: Sorting data\n",
    "The **.sort_values()** function sorts data in ascending order. Use sort_values() to order `penguins` by bill length, from smallest to largest. Then order `penguins` by bill length from largest to smallest.  \n",
    "\n",
    "- Use the `by` argument to specify which column(s) to sort\n",
    "- Use the `ascending=False` argument to sort in descending order\n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) for .sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort penguins by bill length, smallest to largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort penguins by bill length, largest to smallest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort a dataframe by multiple variables by passing a list of column names into the `by` argument.   \n",
    "Sort `penguins` first by year, then by bill length in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort penguins by year, then bill length "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 10: Basic calculations  \n",
    "\n",
    "The pandas library includes computational tools to analyze a dataframe. These can give us summary statistics like **.mean()** or **.median()**, or more advanced statistics like correlation (**.corr()**)\n",
    "\n",
    "[More on computation](https://pandas.pydata.org/docs/user_guide/computation.html) in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Write code to find the mean value for each of the numeric variables and the correlation between numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mean of each numeric variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 11: Grouping and aggregating data\n",
    "\n",
    "The **.groupby()** function separates a dataframe into groups based on the dataframe's columns. This function uses a split-apply-combine process:   \n",
    "- Splitting the data into groups based on some criteria\n",
    "- Applying a function to each group independently\n",
    "- Combining the results into a data structure   \n",
    "\n",
    "The .groupby() function keeps track of which rows of the dataframe belong to each group. The function returns a GroupBy object that is not very informative on its own. We can see what is inside of a GroupBy object by adding additional methods like **.get_group()**, **.groups**, or **.size()**.  We can also aggregate data within groups by adding functions like **.sum()** or **.mean()**.   \n",
    "\n",
    "[Documentation](https://pandas.pydata.org/docs/reference/groupby.html) for .groupby()   \n",
    "\n",
    "[More on the split-apply-combine process](https://pandas.pydata.org/docs/user_guide/groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: Group `penguins` by species. Show the dataframe for Gentoo penguins.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2: Group `penguins` by species. Calculate the mean for each of the numeric variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3: Group `penguins` by species and island. Show the dataframe for Adelie penguins on Biscoe island.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Group `penguins` by species and island. Get a count of how many penguins of each species were on each island.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resources section links:\n",
    "[Additional Practice](#Additional-Practice)   \n",
    "[Resources](#Resources)   \n",
    "[Questions?](#Questions?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Additional Practice\n",
    "Below are a few additional questions to continue practicing pandas functions. Answers provided in the answer key are just suggestions; there are many ways to solve these problems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Practice 1: Extract a dataset of just Gentoo penguins**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice 2: Which species had the highest number of male penguins in 2007? In 2009?**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice 3: How many total penguins were on each island in each year? How many penguins of each species were on each island, in each year?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice 4: For Adelie penguins in 2009, what percentage of the total population was female?**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__pandas Resources__   \n",
    "[pandas Official Documentation](https://pandas.pydata.org/pandas-docs/stable/)   \n",
    "[pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html)   \n",
    "[Comparing pandas to R programming](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html)   \n",
    "Comparing pandas to [Excel](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_spreadsheets.html), [SQL](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html), [SAS](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sas.html), and [Stata](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_stata.html)   \n",
    "\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/) - contains articles on Python and other programming languages, from beginner to expert levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__A few more things pandas can do:__   \n",
    "Pivot tables and reshaping datasets - [blog post with images](https://nikgrozev.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/), [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)   \n",
    "\n",
    "Merging, joining and comparing datasets - [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html), [.join() function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html), [tutorial with images](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/08_combine_dataframes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Jupyter Notebooks Resources__   \n",
    "[Project Jupyter](https://jupyter.org/) - organization behind Jupyter Notebooks   \n",
    "[Anaconda](https://www.anaconda.com/) - environment manager and GUI for launching Jupyter Notebooks  \n",
    "[RISE slideshow extension for Jupyter Notebooks](https://rise.readthedocs.io/en/stable/)   \n",
    "[Guide to interactive notebooks](https://morphocode.com/interactive-notebooks-data-analysis-visualization/)   \n",
    "[Basic Markdown syntax](https://www.markdownguide.org/basic-syntax) for formatting text elements   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Conferences__   \n",
    "[Pycon 2022](https://us.pycon.org/2022/) - annual Python users conference, past talks [available on Youtube](https://www.youtube.com/channel/UCMjMBMGt0WJQLeluw6qNJuA)     \n",
    "[PyData conferences and meetups](https://pydata.org/)   \n",
    "[SciPy conference](http://conference.scipy.org/)   \n",
    "[More Python community events](https://www.python.org/community/workshops/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to visualize your data? Take our [Data Visualization in Python](https://jhu.libcal.com/event/8219524) workshop on Tuesday November 16\n",
    "### [Register here](https://jhu.libcal.com/event/8219524)   \n",
    "\n",
    "<img src=\"./Images/matplotlib_logo.svg\" width='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Take our survey to help us improve this workshop:   \n",
    "### https://www.surveymonkey.com/r/IntroPandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?   \n",
    "\n",
    "## Contact us at dataservices@jhu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### About this Presentation  \n",
    "This presentation was created using Jupyter Notebooks version 6.1.4 and the RISE notebook extension version 5.6.1.    \n",
    "\n",
    "### Terms of Use \n",
    "The presentation materials are licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/), attributable to Data Services, Johns Hopkins University.   \n",
    "\n",
    "Please cite this material as:\n",
    "\n",
    "> Johns Hopkins University Data Services. (2021, November 9). Data Wrangling in Python: Introduction to the pandas library [workshop presentation]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
